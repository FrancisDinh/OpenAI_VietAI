{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\" ## To configure OpenAI API\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\" ## To configure langchain connections with OpenAI\n",
    "doc_path = \"Deep Learning.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 5432, which is longer than the specified 4000\n",
      "Created a chunk of size 7851, which is longer than the specified 4000\n"
     ]
    }
   ],
   "source": [
    "pdf_reader = PdfReader(doc_path)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty string to store the extracted text from the PDF\n",
    "text = \"\"\n",
    "\n",
    "# Iterate through the pages of the PDF and extract text from each page\n",
    "for i, page in enumerate(pdf_reader.pages):\n",
    "    text += f\"### Page {i}:\\n\\n\" + page.extract_text()\n",
    "\n",
    "# Split the text into chunks using Langchain's CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"### \",\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "chunks = text_splitter.split_text(text)\n",
    "# Convert the chunks of text into embeddings to form a knowledge base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "knowledge_base = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAGBot import create_qa_chain, simple_ask_question, answer_from_doc, answer_retrieve_new_page, \\\n",
    "answer_define_page, answer_out_of_context\n",
    "from utils import read_pdf, process_docs, get_pdf_len, search_doc_from_knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_reader = read_pdf(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pdf_len(pdf_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 5432, which is longer than the specified 4000\n",
      "Created a chunk of size 7851, which is longer than the specified 4000\n"
     ]
    }
   ],
   "source": [
    "knowledge_base = process_docs(pdf_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Page 0:\\n\\nCour se summar y\\nHere are the course summary as its given on the course link:\\nIf you want to break into cutting-edge AI, this course will help you do so. Deep learning engineers are highly sought\\nafter, and mastering deep learning will give you numerous new career opportunities. Deep learning is also a new\\n\"superpower\" that will let you build AI systems that just weren\\'t possible a few years ago.\\nIn this course, you will learn the foundations of deep learning. When you finish this class, you will:\\nUnderstand the major technology trends driving Deep Learning\\nBe able to build, train and apply fully connected deep neural networks\\nKnow how to implement efficient (vectorized) neural networks\\nUnderstand the key parameters in a neural network\\'s architecture\\nThis course also teaches you how Deep Learning actually works, rather than presenting only a cursory or surface-level\\ndescription. So after completing it, you will be able to apply deep learning to a your own applications. If you are looking\\nfor a job in AI, after this course you will also be able to answer basic interview questions.\\nIntroduction t o deep learning\\nBe able to explain the major trends driving the rise of deep learning, and understand where and how it is applied today.\\nWhat is a (Neural Netw ork) NN?\\nSingle neuron == linear regression without applying activation(perceptron)\\nBasically a single neuron will calculate weighted sum of input(W.T*X) and then we can set a threshold to predict output\\nin a perceptron. If weighted sum of input cross the threshold, perceptron fires and if not then perceptron doesn\\'t\\npredict.\\nPerceptron can take real values input or boolean values.\\nActually, when w â‹…x+b=0 the perceptron outputs 0.\\nDisadvantage of perceptron is that it only output binary values and if we try to give small change in weight and bais\\nthen perceptron can flip the output. W e need some system which can modify the output slightly according to small\\nchange in weight and bias. Here comes sigmoid function in picture.\\nIf we change perceptron with a sigmoid function, then we can make slight change in output.\\ne.g. output in perceptron = 0, you slightly changed weight and bias, output becomes = 1 but actual output is 0.7. In case\\nof sigmoid, output1 = 0, slight change in weight and bias, output = 0.7.\\nIf we apply sigmoid activation function then Single neuron will act as Logistic R egression.\\nwe can understand difference between perceptron and sigmoid function by looking at sigmoid function graph.\\nSimple NN graph:\\nImage taken from tutorialspoint.com\\nRELU stands for rectified linear unit is the most popular activation function right now that makes deep NNs train faster\\nnow.\\nHidden layers predicts connection between inputs automatically, thats what deep learning is good at.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = search_doc_from_knowledge_base(knowledge_base, \"what is a neural network\",0.5)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tung/miniconda3/envs/py311/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/tung/miniconda3/envs/py311/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "chain = create_qa_chain(model_name='gpt-3.5-turbo',temperature=0,max_tokens=100, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = answer_from_doc(chain, knowledge_base, \"what is a neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A loss function is a mathematical function that measures how well a machine learning model is performing. It quantifies the difference between the predicted output of the model and the actual output. The goal is to minimize the loss function, as a lower value indicates better performance of the model.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_retrieve_new_page(chain, knowledge_base, doc, \"what is a lost function\", retrieve_new_page=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A loss function is a mathematical function that measures the difference between the predicted output of a machine learning model and the actual output. It quantifies the error or loss of the model's predictions and is used to optimize the model's parameters during training. In the given context, the loss function is used to measure the similarity distance between images in a Siamese network for face recognition.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_retrieve_new_page(chain, knowledge_base, doc, \"what is a lost function\", retrieve_new_page=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The given context does not provide any information about L2 loss.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_define_page(chain, \"what is L2 loss\", pdf_reader, [9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_out_of_context(chain, knowledge_base, \"who is Elon Musk\", retrieve_external_knowledge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reponse using external knowledge\\n\\nA large language model is a type of machine learning model that has been trained on a massive amount of text data to understand and generate human-like language. It uses deep learning techniques, such as neural networks, to learn the patterns and relationships between words, phrases, and sentences. These models are capable of generating coherent and contextually relevant text, including essays, stories, news articles, and even poems. Some examples of large language models include GPT-3 (Generative Pretrained Transformer 3), BERT (Bidirectional Encoder Representations from Transformers), and T5 (Text-to-Text Transfer Transformer). These models have a wide range of applications, including natural language processing tasks, text generation, chatbots, and content creation.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_out_of_context(chain, knowledge_base, \"what is large language model\", retrieve_external_knowledge=True, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A neural network is a computational model that is inspired by the structure and functioning of the human brain. It consists of interconnected nodes, called neurons, which are organized into layers. Each neuron takes input, performs a mathematical operation on it, and produces an output. The outputs from one layer of neurons serve as inputs to the next layer, allowing the network to learn and make predictions or classifications.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAGBot_functions import answer_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yes_no(answer):\n",
    "    question_full= f\"\"\"\n",
    "    Does the answer contain a positive word, such as: yes, yeah, go ahead, approval? Answer only True or False \n",
    "    \n",
    "    ###\n",
    "    Answer: {answer}\n",
    "    \"\"\"\n",
    "    return answer_default(question_full)\n",
    "\n",
    "def is_same_page(question):\n",
    "    question_full= f\"\"\"\n",
    "    Does the question contain 'the same page' or in the 'current context' or anything similar? Answer only True or False\n",
    "    Example: \n",
    "    what is a loss function, using the same page => Return True\n",
    "    Can you look for the answer to what is a neural network in page 1, 2 and also 3 => Return False\n",
    "    \n",
    "    ###\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return answer_default(question_full)\n",
    "\n",
    "def has_page_numbers(question):\n",
    "    question_full= f\"\"\"\n",
    "    Does the below input contain page numbers? If yes, which page, answer as a list of integer. If not, return an empty list \n",
    "    \n",
    "    ###\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return answer_default(question_full)\n",
    "\n",
    "def extract_core_question(question):\n",
    "    question_full= f\"\"\"\n",
    "    what is the most important part of the question?  Remove context such as: page number and same page.\n",
    "    \n",
    "    ###\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return answer_default(question_full)\n",
    "\n",
    "def is_question(text):\n",
    "    question_full= f\"\"\"\n",
    "    Is this input a question or not? Answer only True or False\n",
    "    \n",
    "    ###\n",
    "    Input: {text}\n",
    "    \"\"\"\n",
    "    return answer_default(question_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_yes_no(\"Yeah, go ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_same_page(\"what is a loss function, using the same page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 2, 3]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_page_numbers(\"Can you look for the answer to what is a neural network in page 1, 2 and also 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a neural network?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_core_question(\"Can you look for the answer to what is a neural network in page 1, 2 and also 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes_no': False, 'same_page': False, 'pages': [], 'external': False}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "input_string = \"{\\n    'yes_no': False,\\n    'same_page': False,\\n    'pages': [],\\n    'external': False\\n}\"\n",
    "\n",
    "# Safely evaluate the input string as a dictionary using ast.literal_eval\n",
    "output_dict = ast.literal_eval(input_string)\n",
    "\n",
    "print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
